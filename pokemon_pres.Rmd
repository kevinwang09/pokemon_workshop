---
title: "Pokemons"
author: "Kevin Wang"
date: "9 June 2017"
output:
  ioslides_presentation:
    fig_height: 6
    fig_width: 6
    incremental: yes
    self_contained: yes
    widescreen: yes
always_allow_html: yes
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(comment=NA, warning=FALSE, message=FALSE)
library(tidyverse)

options(tibble.print_max = 10, tibble.print_min = 5)
```

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>

# S0: Prior to lecture

## Preparing for this lecture {.build}

+ All materials are on https://github.com/kevinwang09/pokemon_workshop.

+ Data was obtained from https://www.kaggle.com/alopez247/pokemon.

+ Please run these codes on your laptop prior to the lecture. 

```{r, eval = F}
install.packages("tidyverse") ## Might be a while...
install.packages("janitor")
```

```{r}
library(tidyverse)
library(dplyr)
```


# Reading in data

## Reading in data {.build}

+ Older way of reading data: `read.csv`, `read.delim`, ... 

+ Mordernised data reading: 

    - `readr`: `read_csv`, `read_delim`, better handling of variable types.
    - `readxl`: `read_excel`, better handling of JavaScripts.
    - `haven`: `read_sas()`, reading SPSS, Stata and SAS files from R 

```{r readingPokemon}
rawDat = read_csv("pokemon_alopez247.csv")
```


# Clean Coding

## Piping {.build}

+ The "inside out" structure of coding isn't great for human reading.

+ We introduce a new notation: " x %>% f " means "f(x)". We call this operation as "x pipe f".

+ We now read code from left to right.

+ Keyboard shortcut is Cmd+shift+M.

```{r piping}
rawDat %>% summary
## summary(rawDat)
```



# `janitor`: basic cleaning {.build}

+ Clean up the bad column names.

```{r janitor}
library(janitor)
varCleanData = rawDat %>% clean_names
# varCleanData %>% View
```

+ There are also other cleaning functions and tabular functions. 

```{r janitor2}
tabyl(rawDat$Generation)
```

# `dplyr`: data manipulator

## *mutate* create new columns {.build}

```{r dplyr_mutate}
library(dplyr)
glimpse(varCleanData)

cleanData = varCleanData %>% 
  mutate(islegendary = as.logical(islegendary),
         hasgender = ifelse(hasgender == "True", TRUE, FALSE),
         hasmegaevolution = case_when(
           hasmegaevolution == "True" ~ TRUE,
           hasmegaevolution == "False" ~ FALSE),
         generation = as.factor(generation)
         )
```


## *rename* change column names {.build}

```{r dplyr_rename}
glimpse(cleanData)

cleanData = cleanData %>% 
  dplyr::rename(
    special_attack = sp_atk,
    special_defense = sp_def,
    height = height_m,
    weight = weight_kg
  )

glimpse(cleanData)

write_csv(cleanData, path = "pokemon_cleanData.csv")
```



## Summary statistics using *group_by* + *summarise* {.build}

```{r groupSummarise}
groupType1 = cleanData %>% 
  group_by(type_1)
  
groupType1

groupType1 %>% 
  dplyr::summarise(medianAttack = median(attack))
```


## *filter* is for row  {.build}

```{r filter}
cleanData = read_csv("pokemon_cleanData.csv")

gen1Legends = cleanData %>% 
  filter(generation == 1,
         islegendary)

glimpse(gen1Legends)
```






## *select* is for column {.build}
```{r select}

basicStats = cleanData %>% 
  dplyr::select(name,
                hp:speed,
                contains("type"))
basicStats
```


















# `ggplot2`: data visualisation

## How to inform? {.build}
```{r}
library(forcats)
typePlotdf = basicStats %>%
  gather(key = typeKey,
         value = type,
         type_1,type_2) %>% 
  select(-typeKey) %>% 
  mutate(type = fct_reorder(type, attack)) %>% 
  gather(key = statType,
         value = statValue,
         hp:speed) %>% 
  remove_missing()

typePlotdf %>% 
  group_by(type, statType) %>% 
  dplyr::summarise(medianStats = median(statValue)) %>% 
  spread(key = statType,
         value = medianStats)


typePlotdf %>% 
  ggplot(aes(x = type, y = statValue)) +
  geom_jitter(alpha = 0.2) +
  geom_boxplot(width = 0.2) + 
  facet_wrap(~statType)
```






# Advanced `dplyr`

## Advanced selection using *select_if*  {.build}

```{r select_if num}
numFunction = function(x){is.integer(x)|is.numeric(x)}

numVarsOnly = cleanData %>% 
  select_if(.predicate = numFunction) %>% 
  remove_missing()

numVarsOnly
```




# Time for some statistics

## Correlation {.build}

```{r d3heatmap}
library(d3heatmap)


d3heatmap(cor(numVarsOnly), 
          colors = c("blue", "white", "red"))

## Even better colours.
# goodColours = RColorBrewer::brewer.pal(n = 9, name = "Spectral") %>% rev
```




## Principal Component Analysis {.build}

+ PCA is a dimension reduction method. It "projects" a high dimensional data into a lower dimension subspace.

+ The projection is such that the new data: 

    - Preserves the data size ($n$ rows times $p$ columns).
    - Each column is **uncorrelated** to each other, but;
    - They are linear combination of the original columns.
    - The correlation structure of the original data is preserved.

+ In short, PCA is a very powerful technique that transform the data into a lower, more interpretable/visualisable dimension. 

+ We will PCA on the numerical data matrix. 


```{r pcaPlot, eval = F}
pcaData = numVarsOnly %>% select(-number, -generation)
pcaObj = prcomp(pcaData, scale. = T)
ggbiplot::ggbiplot(pcaObj)

# ggbiplot::ggbiplot
```





## t-sne
```{r}
library(Rtsne)
tsneObj = Rtsne(X = numVarsOnly %>% select(-number, -generation), perplexity = 30)
tsnePlotdf = data.frame(tsneObj$Y[,1:2],
                        numVarsOnly) %>% 
  left_join(cleanData)

ggplot(tsnePlotdf) +
  geom_point(aes(x = X1, y = X2, 
                 colour = as.factor(generation))) + 
  theme_bw() + 
  theme(legend.position = "bottom")
```












# Advanced topics
## data merging: *dplyr::left_join* {.build}

+ Data integration is very easy to mess up. 

+ `dplyr` offers several ways of doing this: `left_join`, `right_join`, `inner_join`, `full_join`, ... etc. 

```{r left_join, eval = F}
visData = left_join(x = pcaPlotdf,
                    y = cleanData)

glimpse(visData)

ggplot(data = visData,
       aes(x = PC1, 
           y = PC2,
           size = total,
           colour = islegendary
           )) +
  geom_point(shape = 1, stroke = 1.2) +
  theme_bw()
```



## *ggimage* {.build}

```{r pokemonPlotdf, eval = F}
library(ggimage)
pokemonPlotdf = visData %>% 
  filter(generation == 1) %>% ## Higher generations are not supported. 
  mutate(image = ifelse(PC1 > 3 | PC2 < -3, tolower(name), NA))


pokemonPlotdf %>% 
  ggplot(aes(x = PC1, y = PC2)) + 
  geom_point(shape = 1) +
  geom_pokemon(aes(image = image)) +
  theme_bw()
```


## ggmap {.build}

```{r, eval = F, echo = F}
library(ggmap)
library(nycflights13)

us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")


# ggmap(map) + 
#   geom_point(aes(x = lon, y = lat), data = airports)


redAirports = dplyr::select(airports, faa, lat, lon)

flightsAirports = flights %>% 
  # filter(origin == "JFK") %>% 
  dplyr::select(origin, dest) %>% 
  left_join(redAirports, by = c("origin" = "faa")) %>% 
  dplyr::rename(lat_ori = lat,
                lon_ori = lon) %>% 
  left_join(redAirports, by = c("dest" = "faa")) %>% 
  dplyr::rename(lat_dest = lat,
                lon_dest = lon) %>% 
  group_by(origin, dest) %>%
  mutate(numFlights = n()) %>%
  distinct()



ggmap(map) + 
  geom_point(aes(x = lon_dest, y = lat_dest), data = flightsAirports) + 
  geom_curve(aes(x = lon_ori, y = lat_ori, 
                 xend = lon_dest, yend = lat_dest, 
                 alpha = numFlights,
                 size = numFlights,
                 colour = origin), 
             data = flightsAirports) +
  facet_grid(~origin) +
  coord_cartesian() +
  scale_size_continuous(range = c(0.1,2)) + 
  scale_color_brewer(palette = "Set1")
```


## Type chart
```{r}
typeData = read_csv("typeChart.csv") 
typeNames = tolower(typeData$X1)
typeData = typeData[,-1] %>% as.data.frame() %>% as.matrix
colnames(typeData) = rownames(typeData) = typeNames

library(reshape2)
typeDf = melt(typeData,
              varnames = c("attack", "defend"),
              value.name = "effect") %>% 
  mutate(effect = case_when(
    is.na(effect) ~ "usual",
    effect == 0 ~ "noEff",
    effect == 0.5 ~ "notVeryEff",
    effect == 2 ~ "veryEff"
  ))

library(visNetwork)


nodes = tibble(id = unique(typeDf$attack),
               label = id)
edges = tibble(from = typeDf$attack,
                   to = typeDf$defend,
                   label = typeDf$effect,
                   arrows = "to") %>% 
  dplyr::filter(label != "usual") %>% 
  mutate(color = case_when(
    label == "noEff" ~ "blue",
    label == "notVeryEff" ~ "purple",
    label == "veryEff" ~ "red"
  ))

visNetwork(nodes, edges)
```



# References
## References
```{r sessionInfo}
sessionInfo()
```